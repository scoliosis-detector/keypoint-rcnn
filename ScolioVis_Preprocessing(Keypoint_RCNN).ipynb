{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lZKg9NEJTViO"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "boostnet_dir = \"./datasets/labeldata\" \n",
    "output_dir = \"./datasets/keypointrcnn_data\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kyo1mH0cTWoV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import imagesize\n",
    "# import pybboxes as pbx\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sU6VE5gTTY0S"
   },
   "outputs": [],
   "source": [
    "# 주어진 랜드마크를 x좌표와 y좌표로 나누어 반환\n",
    "def split_XY(landmarks):\n",
    "    first_half = landmarks[:68]\n",
    "    second_half = landmarks[68:]\n",
    "    return (first_half, second_half)\n",
    "\n",
    "# 주어진 x, y 좌표 목록에서 최소 및 최대 값을 찾아 bounding box의 경계 값을 반환\n",
    "# 아래의 get_bounding_boxes에서 경계를 찾는 데 활용\n",
    "def find_min_max(x, y):\n",
    "    # 최소값 계산\n",
    "    x_min = min(x)\n",
    "    y_min = min(y)\n",
    "\n",
    "    # 최대값 계산\n",
    "    x_max = max(x)\n",
    "    y_max = max(y)\n",
    "    return(x_min, y_min, x_max, y_max)\n",
    "\n",
    "# 정규화된 랜드마크를 기반으로 bounding box를 계산하여 반환\n",
    "# bounding box : 각 척추를 감싸는 사각형의 경계, 특정 척추(keypoint)들을 포함하는 경계 좌표라고 생각하면 됨 \n",
    "# 척추의 위치를 정의하는 데 사용 => 모델이 bounding box를 통해 객체(척추)를 식별하고 위치를 파악\n",
    "def get_bounding_boxes(normalized_landmarks):\n",
    "  \"\"\"returns bounding boxes in ``[x1,y1,x2,y2]`` normalized format,\n",
    "    ``0 <= x1 < x2 <= 1`` and ``0 <= y1 < y2 <= 1``\n",
    "  \"\"\"\n",
    "  x_list, y_list = split_XY(normalized_landmarks)\n",
    "  bounding_boxes = []\n",
    "  POINTS_PER_VERTEBRAE = 4  # 각 척추에 대한 포인트 수\n",
    "  VERTEBRAE_COUNT = int(len(x_list) / POINTS_PER_VERTEBRAE)  # 17 : 총 척추의 수\n",
    "\n",
    "  for i in range(VERTEBRAE_COUNT):\n",
    "    x = x_list[POINTS_PER_VERTEBRAE * i: POINTS_PER_VERTEBRAE * i + 4]\n",
    "    y = y_list[POINTS_PER_VERTEBRAE * i: POINTS_PER_VERTEBRAE * i + 4]\n",
    "    min_max = find_min_max(x,y)\n",
    "    bounding_boxes.append((min_max[0],min_max[1],min_max[2],min_max[3]))\n",
    "\n",
    "  return bounding_boxes\n",
    "\n",
    "# 정규화된 랜드마크를 사용하여 각 인스턴스의 키포인트를 생성하고, 모델이 사용할 수 있는 형식으로 반환\n",
    "# 반환 형식 : [x, y, visibility]\n",
    "# keypoint : 척추의 곡률을 평가하는 데 필요한 주요 포인트, 각 척추들의 위치 좌표라고 생각하면 됨 \n",
    "def get_keypoints(normalized_landmarks):\n",
    "  \"\"\"returns keypoints (normalized), where\n",
    "  keypoints (FloatTensor[N, K, 3]): the K keypoints location for each of the N instances, in the\n",
    "        format [x, y, visibility], where visibility=0 means that the keypoint is not visible.\n",
    "  \"\"\"\n",
    "  x_list, y_list = split_XY(normalized_landmarks)\n",
    "\n",
    "  keypoints = [] # 전체 이미지의 keypoint 저장\n",
    "  POINTS_PER_VERTEBRAE = 4  # 각 인스턴스에 대한 포인트 수\n",
    "  VERTEBRAE_COUNT = int(len(x_list) / POINTS_PER_VERTEBRAE)  # 17 : 총 인스턴스 수\n",
    "\n",
    "  # 각 인스턴스에 대해 반복문 \n",
    "  for i in range(VERTEBRAE_COUNT):\n",
    "    x_points = x_list[POINTS_PER_VERTEBRAE * i: POINTS_PER_VERTEBRAE * i + 4]\n",
    "    y_points = y_list[POINTS_PER_VERTEBRAE * i: POINTS_PER_VERTEBRAE * i + 4]\n",
    "\n",
    "    # [x, y, visibility] 형식의 리스트 생성\n",
    "    # visibility는 항상 1로 설정 : 해당 keypoint가 보이는 상태\n",
    "    # 같은 bounding box에 포함되는 keypoint들은 하나의 인스턴스에 속함\n",
    "    instance_keypoints = [[x,y,1] for x, y in zip(x_points, y_points)]\n",
    "    keypoints.append(instance_keypoints)\n",
    "\n",
    "  return keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8hl39k_sTYvo"
   },
   "outputs": [],
   "source": [
    "# 주어진 이미지와 랜드마크를 사용하여 KeyPoint R-CNN format의 주석 생성\n",
    "# 이미지의 크기를 기반으로 bounding box와 keypoint를 비정규화하여 반환\n",
    "def preprocess_image(image_dir, landmarks):\n",
    "  \"\"\"return KeyPoint RCNN Format annotation of 1 image\n",
    "\n",
    "  During training, the model expects both the input tensors, as well as a targets (list of dictionary),\n",
    "  containing:\n",
    "      - boxes (``FloatTensor[N, 4]``): the ground-truth boxes in ``[x1, y1, x2, y2]`` format, with\n",
    "          ``0 <= x1 < x2 <= W`` and ``0 <= y1 < y2 <= H``.\n",
    "      - labels (Int64Tensor[N]): the class label for each ground-truth box\n",
    "      - keypoints (FloatTensor[N, K, 3]): the K keypoints location for each of the N instances, in the\n",
    "        format [x, y, visibility], where visibility=0 means that the keypoint is not visible.\n",
    "  \"\"\"\n",
    "\n",
    "  # width, height = imagesize.get(image_dir)  # 이미지 크기 가져오기 (비정규화할 때 사용)\n",
    "  voc_bboxes = get_bounding_boxes(landmarks)\n",
    "  keypoints = get_keypoints(landmarks)\n",
    "\n",
    "  # voc_bboxes = [[int(bbox[0]*width), int(bbox[1]*height), int(bbox[2]*width), int(bbox[3]*height)] for bbox in voc_bboxes]  # 비정규화\n",
    "  labels = [0 for bbox in voc_bboxes] # 모든 bounding box에 대해 레이블 생성 : 모든 bounding box가 척추이므로 0으로 설정\n",
    "\n",
    "  # 각 keypoint 비정규화 \n",
    "  # x, y 좌표를 이미지 크기로 곱하여 픽셀 단위로 변환. visibility는 유지 \n",
    "  denormalized_keypoints = []\n",
    "  for instance in keypoints:\n",
    "    instance_keypoints = []\n",
    "    for kp in instance:\n",
    "      # instance_keypoints.append([int(kp[0]*width), int(kp[1]*height), kp[2]])\n",
    "      instance_keypoints.append([int(kp[0]), int(kp[1]), kp[2]]) # 비정규화 X\n",
    "    denormalized_keypoints.append(instance_keypoints)\n",
    "\n",
    "  # 반환값 : 딕셔너리\n",
    "  return {\n",
    "      \"boxes\": voc_bboxes, # 비정규화된 bounding box\n",
    "      \"labels\": labels, # 0\n",
    "      \"keypoints\": denormalized_keypoints # 비정규화된 keypoint\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = boostnet_dir + \"/data\"\n",
    "# labels_dir = boostnet_dir + \"/labels\"\n",
    "# splits = ['/test', '/train']\n",
    "\n",
    "# # loop through split\n",
    "# # 각 split에 대해 파일을 읽고 결함 있는 행을 제거한 후, 각 이미지에 대해 주석을 생성하고 JSON 파일로 저장\n",
    "# for split in splits:\n",
    "#     filenames = pd.read_csv(labels_dir+split+\"/filenames.csv\") # indexer\n",
    "#     landmarks_df = pd.read_csv(labels_dir+split+\"/landmarks.csv\")\n",
    "\n",
    "#     print(labels_dir+split+\"/filenames.csv\")\n",
    "#     print(labels_dir+split+\"/landmarks.csv\")\n",
    "#     print()\n",
    "    \n",
    "#     for i, filename in enumerate(filenames.filenames):\n",
    "#         print(data_dir, split, filename, '//////////', landmarks_df.iloc[i].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cu6K-vncTn6G"
   },
   "outputs": [],
   "source": [
    "# boostnet_dir의 데이터를 읽고 전처리하여 output_dir에 저장\n",
    "def preprocess_data(boostnet_dir, output_dir):\n",
    "  data_dir = boostnet_dir + \"/data\"\n",
    "  labels_dir = boostnet_dir + \"/labels\"\n",
    "  splits = ['/test', '/train']\n",
    "\n",
    "  # loop through split\n",
    "  # 각 split에 대해 파일을 읽고 결함 있는 행을 제거한 후, 각 이미지에 대해 주석을 생성하고 JSON 파일로 저장\n",
    "  for split in splits:\n",
    "    filenames = pd.read_csv(labels_dir+split+\"/filenames.csv\") # indexer\n",
    "    landmarks_df = pd.read_csv(labels_dir+split+\"/landmarks.csv\")\n",
    "    landmarks_list = landmarks_df.landmarks.apply(lambda x: [float(y.strip()) for y in x.split(',')])\n",
    "\n",
    "    # loop through image\n",
    "    for i, filename in enumerate(filenames.filenames):\n",
    "      # preprocess_image(image_dir, landmarks) : boxes, laels, keypoints가 포함된 딕셔너리 반환\n",
    "      # preprocess_image 함수를 호출하여 주석(annotation) 생성\n",
    "      annotation = preprocess_image(data_dir+split+\"/\"+filename, landmarks_list[i])\n",
    "\n",
    "      # 주석파일을 저장할 디렉토리 이름 설정\n",
    "      # 테스트 : /val, 훈련 : /train\n",
    "      split_dirname = \"/val\" if split == \"/test\" else \"/train\"\n",
    "\n",
    "      # 출력 디렉토리가 존재하지 않으면 생성\n",
    "      if (not os.path.exists(output_dir)):\n",
    "        os.mkdir(output_dir)\n",
    "      if (not os.path.exists(output_dir+\"/labels\")):\n",
    "        os.mkdir(output_dir+\"/labels\")\n",
    "      if (not os.path.exists(output_dir+\"/labels\"+split_dirname)):\n",
    "        os.mkdir(output_dir+\"/labels\"+split_dirname)\n",
    "\n",
    "      # 생성된 주석을 JSON 형식으로 저장\n",
    "      annotation_filename = os.path.splitext(filename)[0]+\".json\"\n",
    "      with open(output_dir+\"/labels\"+split_dirname+\"/\"+annotation_filename, 'w') as outfile:\n",
    "        json.dump(annotation, outfile)\n",
    "\n",
    "      # 출력 디렉토리에 이미지를 저장할 디렉토리 생성\n",
    "      if (not os.path.exists(output_dir+\"/images\")):\n",
    "        os.mkdir(output_dir+\"/images\")\n",
    "      if (not os.path.exists(output_dir+\"/images\"+split_dirname)):\n",
    "        os.mkdir(output_dir+\"/images\"+split_dirname)\n",
    "\n",
    "      # 원본 이미지를 지정된 출력 디렉토리로 복사\n",
    "      original = data_dir+split+\"/\"+filename\n",
    "      target = output_dir+\"/images/\"+split_dirname\n",
    "\n",
    "      shutil.copy(original, target)\n",
    "  print(f\"Finished writing to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j3FuSiEMgGkB",
    "outputId": "4db9f722-73cc-4bd2-a28d-d24768ba3287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing to ./datasets/keypointrcnn_data\n"
     ]
    }
   ],
   "source": [
    "preprocess_data(boostnet_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMuqIutOnFjZ",
    "outputId": "c3563bf3-ca3a-489a-f695-d88bde640bfd"
   },
   "outputs": [],
   "source": [
    "# change rcnn_data to the output_dir\n",
    "# !zip -r keypointrcnn_data.zip rcnn_data"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "scoliosis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
